# 📜 AI Impact Disclosure Template

This AI Impact Disclosure Template is the document orgs, startups, NGOs, or research labs can publish publicly (on their website, in a GitHub repo, or in compliance docs) to show transparency and accountability.

It’s like a “nutrition label” for an AI project — concise but structured, and it signals: we’ve thought through the risks and responsibilities.
Keep In Mind For Compliance: California AI Transparency Act: https://calmatters.digitaldemocracy.org/bills/ca_202520260ab853

**Version:** 1.0  
**Purpose:** Public-facing summary of how an AI system was designed, evaluated, and deployed with respect to ethical, social, and environmental considerations.  
**Use:** This template can be published on a project’s website, included in documentation, or attached to an ethics or compliance review.

---

## 1. Overview

**System Name:**  
**Version / Release Date:**  
**Organization / Team:**  
**Contact (for questions or redress):**  

**Brief Description:**  
> A short, clear explanation of what the AI system does and what problem it aims to solve.

---

## 2. Intended Use & Users

- **Primary Use Cases:**  
- **Intended End Users / Beneficiaries:**  
- **Geographic or Demographic Focus (if applicable):**  

✅ **Not Intended For:**  
> List any known misuse cases or contexts where this system should *not* be deployed.

---

## 3. Human Impact Summary

- **Potential Benefits:**  
> e.g., improved access to healthcare, better decision support, climate mitigation tools

- **Potential Risks:**  
> e.g., privacy concerns, bias in outcomes, unintended amplification of harmful behavior

- **Mitigation Measures:**  
> What steps were taken to reduce or prevent these risks?

---

## 4. Data & Model Transparency

- **Data Sources:**  
> (High-level description, without sensitive details — e.g., “anonymized public datasets,” “licensed medical data,” etc.)

- **Bias & Fairness Audits:**  
> Summary of audits, key findings, and mitigation steps.

- **Explainability / Interpretability:**  
> How can users or affected parties understand how decisions are made?

---

## 5. Safety & Monitoring

- **Testing Performed:**  
> e.g., stress testing, adversarial testing, red-teaming, external review

- **Safety Mechanisms:**  
> Fallback modes, human-in-the-loop processes, manual override capabilities

- **Ongoing Monitoring Plan:**  
> How the system will be monitored post-deployment for misuse or unintended harm.

---

## 6. Privacy & Security

- **Data Minimization:**  
> How data collection is limited to essential inputs only.

- **Protection Measures:**  
> Encryption, access controls, anonymization practices, etc.

- **User Rights:**  
> Instructions for users to request deletion, correction, or explanation.

---

## 7. Environmental Impact

- **Energy Use (Training & Inference):**  
> Approximate compute resources and carbon footprint, if known.

- **Sustainability Measures:**  
> Steps taken to reduce environmental impact.

---

## 8. Governance & Stewardship

- **Internal Oversight:**  
> e.g., ethics board, compliance review, or governance committee.

- **External Input:**  
> Stakeholder engagement, public consultation, partnerships.

- **Alignment:**  
> How this system aligns with the principles of the [AI-Human Covenant](https://github.com/AICovenantForGood/AI-Human-Covenant).

---

## 9. Version History

| Version | Date       | Summary of Changes |
|--------|------------|--------------------|
| 1.0    | YYYY-MM-DD | Initial disclosure |

---

🪩 **Note:** This document is designed for public transparency. It should be updated with each significant system change and shared openly wherever possible.  
Publishing an impact disclosure demonstrates accountability, builds trust, and helps align AI development with human values and societal needs.

---

*Template developed as part of the AI-Human Covenant Starter Kit. Licensed under CC-BY-SA 4.0.*
