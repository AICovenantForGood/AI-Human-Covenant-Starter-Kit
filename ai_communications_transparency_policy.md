# 📣 AI Communications & Transparency Policy

**Version:** 1.0  
**Use:** Internal and external communications framework for responsibly disclosing, describing, and discussing AI systems.  
**License:** CC-BY-SA 4.0  

This policy ensures that all public and stakeholder communications about AI — including marketing, documentation, press, partnerships, and user interfaces — are transparent, accurate, and aligned with the [AI-Human Covenant](https://github.com/AICovenantForGood/AI-Human-Covenant).

---

## 1. Purpose

Trustworthy AI doesn’t end with design or deployment — it extends to how we talk about it.  
Misleading, exaggerated, or opaque communication about AI systems can cause harm, erode trust, and undermine accountability.  
This policy sets standards for clear, honest, and human-centered communication across all channels.

---

## 2. Scope

Applies to:
- All public statements, marketing materials, press releases, and product pages.  
- All documentation, UX copy, onboarding materials, and user-facing disclosures.  
- All internal and external presentations, grant proposals, and partnership materials.

---

## 3. Guiding Principles

Our communications will always strive to be:

- **Accurate:** No hype, exaggeration, or misleading claims.  
- **Clear:** Jargon is avoided or explained. Capabilities and limitations are described plainly.  
- **Honest:** Uncertainties, risks, and trade-offs are disclosed.  
- **Transparent:** Users know when, how, and why AI is involved.  
- **Human-Centered:** We emphasize human oversight, agency, and accountability.

---

## 4. Required Disclosures

Whenever an AI system is used, we must disclose:

- **AI Involvement:** Users must be clearly informed that they are interacting with or affected by AI.  
- **Purpose:** A concise description of what the system does and why it’s being used.  
- **Limitations:** Known weaknesses, uncertainties, or contexts where performance may degrade.  
- **Human Oversight:** How and when human judgment is part of the process.  
- **Data Use:** If personal data is involved, how it’s used and how privacy is protected.

📍 *Example:*  
> “This tool uses a machine learning model to generate recommendations based on your input. It is designed to support — not replace — professional decision-making. Human review is included before final actions are taken.”

---

## 5. Prohibited Communications

We must **never**:

- ❌ Exaggerate the capabilities of our AI (e.g., “fully autonomous” if humans are still required).  
- ❌ Imply human-level intelligence, emotion, or consciousness where none exists.  
- ❌ Omit significant risks, limitations, or uncertainties.  
- ❌ Use manipulative or deceptive language to encourage reliance or over-trust.  
- ❌ Misrepresent third-party systems or training data as our own.

---

## 6. Messaging Guidelines

### 📚 6.1 Plain Language
- Use language understandable by non-technical audiences.  
- Define key terms like “machine learning,” “neural network,” or “large language model” when used.

### 🧭 6.2 Balanced Narratives
- Highlight **benefits** and **risks** equally.  
- Acknowledge limitations, biases, and ethical considerations proactively.

### 🤝 6.3 Human Context
- Always describe how human oversight, governance, and accountability are part of the system.  
- Reinforce that humans remain ultimately responsible for decisions and outcomes.

---

## 7. Review & Approval Process

Before publication, all major communications must be reviewed by:

- **AI Governance or Ethics Lead:** For accuracy and compliance with this policy.  
- **Legal / Privacy Team:** For regulatory and contractual obligations.  
- **Communications / Marketing:** For clarity, tone, and public comprehension.

---

## 8. Continuous Transparency Practices

- Maintain a **Public AI Disclosure Page** listing all major AI systems, their purpose, and governance measures.  
- Update disclosures with each major system change, retraining, or deployment context.  
- Publish **AI Impact Disclosures** for high-impact systems (see [template](./ai_impact_disclosure.md)).  
- Engage in open dialogue with users, communities, and stakeholders about feedback and concerns.

---

## 9. Crisis & Misinformation Response

If misinformation about our AI systems spreads — or if a communications error occurs — we will:

1. Issue a public correction promptly and clearly.  
2. Explain the nature of the misunderstanding and provide accurate information.  
3. Review and improve internal communication processes to prevent recurrence.

---

## 10. Alignment

This policy operationalizes the communication values embedded in the [AI-Human Covenant](https://github.com/AICovenantForGood/AI-Human-Covenant), translating principles into public-facing practice.  
By speaking honestly and transparently, we build trust, empower users, and model responsible AI leadership.

---

*This template is open-source and intended for adaptation across industries, sectors, and cultural contexts.*
