# ğŸ§ª AI Risk Assessment â€“ Lite Version (Quick Scan)

**Version:** 1.0  
**Use case:** Early-stage review (prototype, concept, or MVP)  
**Time:** ~10â€“15 min

This short checklist helps teams quickly identify major ethical, social, and governance risks early in the design process.  
Itâ€™s designed to be *fast and conversational*, not exhaustive.

---

## ğŸ§ Human & Social Impact
- [ ] Could this system harm people or communities if misused?  
- [ ] Might it disadvantage any particular group?  
- [ ] Would I feel comfortable if this affected *me* or someone I care about?

---

## ğŸ”’ Safety & Accountability
- [ ] Is there a clear person or team accountable for the systemâ€™s outcomes?  
- [ ] Do we know what happens if the system fails or is misused?  
- [ ] Are we collecting only the data we truly need â€” and keeping it secure?

---

## âš–ï¸ Bias & Fairness
- [ ] Have we thought about who might be excluded or treated unfairly?  
- [ ] Are we testing outputs on diverse examples?

---

## ğŸ” Transparency & Trust
- [ ] Will users know theyâ€™re interacting with AI?  
- [ ] Can we explain how this system works at a high level?  
- [ ] Would we be comfortable showing its logic to the public?

---

## ğŸŒ Long-Term Considerations
- [ ] Could this scale in a way that causes harm or amplifies risks?  
- [ ] Is the environmental cost reasonable and measured?  
- [ ] Are we aligned with broader principles like the **AI-Human Covenant**?

---

âœ… **Tip:** If you answer â€œnoâ€ or â€œnot sureâ€ to more than 2 questions, itâ€™s worth a deeper review before moving forward.

---

*This lite checklist is a starting point â€” not a substitute for comprehensive risk assessment.*
