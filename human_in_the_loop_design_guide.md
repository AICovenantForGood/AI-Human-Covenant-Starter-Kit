# ğŸ§‘â€ğŸ’» Human-in-the-Loop (HITL) Design Guide

This world-class template version is for design teams, policy makers, and procurement processes. Itâ€™s one of the most cited governance requirements in EU AI Act compliance and ISO/IEC standards.

**Version:** 1.0  
**Use:** Design and engineering guide for ensuring meaningful human oversight in AI systems.  
**License:** CC-BY-SA 4.0  

This guide helps teams design, build, and deploy AI systems that keep *humans in control* â€” ensuring that human judgment, context, and accountability remain central to decision-making.  
It is designed to align with the [AI-Human Covenant](https://github.com/AICovenantForGood/AI-Human-Covenant).

---

## 1. Purpose

AI systems should **augment** human decision-making, not replace it.  
Meaningful human-in-the-loop (HITL) design ensures that people remain the ultimate decision-makers â€” especially in contexts involving safety, rights, justice, or significant social impact.

---

## 2. When HITL Is Essential

A human-in-the-loop approach is strongly recommended when:

- âœ… The AI system impacts peopleâ€™s rights, safety, or livelihoods  
- âœ… Thereâ€™s potential for harm, discrimination, or misuse  
- âœ… Legal, ethical, or regulatory requirements mandate oversight  
- âœ… Human expertise is required to interpret nuanced context  
- âœ… The systemâ€™s confidence is uncertain or variable

---

## 3. Levels of Human Oversight

HITL design can take different forms depending on the context and risk level:

| Level | Description | Example |
|------|-------------|---------|
| **Human-in-the-Loop (HITL)** | Human reviews and approves each AI decision before action. | Medical diagnosis tool requiring doctor sign-off |
| **Human-on-the-Loop (HOTL)** | AI makes decisions autonomously, but humans monitor and can intervene. | Fraud detection system with human override |
| **Human-in-Command (HIC)** | Humans define goals, constraints, and can shut down or redirect the system at any time. | Critical infrastructure AI (e.g., power grid control) |

ğŸ’¡ **Best Practice:** Default to HITL for high-risk scenarios, HOTL for moderate risk, and HIC as a baseline safeguard across all systems.

---

## 4. HITL Design Checklist

### ğŸ§  1. Define Human Roles Clearly
- [ ] Who is responsible for oversight?  
- [ ] What decisions require human review?  
- [ ] What expertise or training do reviewers need?

### ğŸ–¥ï¸ 2. Build Oversight into the Workflow
- [ ] Human approval steps are integrated into UI/UX.  
- [ ] Interfaces present context, confidence scores, and rationale.  
- [ ] Reviewers can approve, reject, or modify outputs easily.

### ğŸ“Š 3. Provide Explainability & Context
- [ ] The system explains *why* it made a recommendation.  
- [ ] Relevant input data and uncertainty levels are visible.  
- [ ] Human reviewers can access audit trails for past decisions.

### âš ï¸ 4. Ensure Override and Fallback
- [ ] Humans can pause, reverse, or override AI actions at any time.  
- [ ] Manual control is possible even if the system is automated.  
- [ ] Emergency stop (â€œkill switchâ€) protocols are documented.

### ğŸ“š 5. Train and Empower Human Operators
- [ ] Oversight staff receive regular training.  
- [ ] Escalation procedures are clear and rehearsed.  
- [ ] Decision-making responsibility is matched with authority.

---

## 5. HITL Design Patterns (Examples)

- ğŸ©º **Review + Approve:** AI drafts a medical report â†’ human doctor reviews â†’ only approved results are published.  
- ğŸ¦ **Alert + Confirm:** AI flags a suspicious transaction â†’ compliance officer reviews before blocking.  
- âš–ï¸ **Score + Override:** AI suggests sentencing range â†’ judge reviews and adjusts based on context.  
- ğŸ›¡ï¸ **Autonomous + Abort:** AI operates autonomously in a safety-critical system â†’ operator can intervene immediately.

---

## 6. Continuous Oversight

HITL is not â€œset it and forget it.â€  
- Conduct periodic audits of human review quality.  
- Monitor decision override rates and patterns.  
- Gather feedback from reviewers to improve system design.  
- Adjust oversight levels as system capabilities and risks evolve.

---

## 7. Alignment with the AI-Human Covenant

HITL embodies the Covenantâ€™s core values:
- **Dignity:** Humans remain ultimate decision-makers.  
- **Accountability:** Responsibility is traceable and enforceable.  
- **Transparency:** Oversight decisions are explainable and auditable.  
- **Stewardship:** AI supports â€” not replaces â€” human judgment.

---

ğŸª© **Key Principle:** True AI stewardship isnâ€™t about automating humans out â€” itâ€™s about amplifying their judgment, care, and creativity.

---

*This guide is open-source and designed to evolve. Adapt it to your context, risk level, and organizational needs.*
