# üõ°Ô∏è AI Risk Assessment Checklist (Starter Template)

**Version:** 1.0  
**Last updated:** YYYY-MM-DD  
**License:** CC-BY-SA 4.0  

This checklist helps teams evaluate potential risks, harms, and unintended consequences when designing, building, and deploying AI systems.  
It is not exhaustive ‚Äî but provides a structured starting point.

---

## 1. Human Impact
- [ ] Could this system negatively affect human dignity, rights, or freedoms?  
- [ ] Have we considered potential harms to vulnerable or marginalized groups?  
- [ ] Is there a clear appeal or redress mechanism for people impacted?  

---

## 2. Safety & Reliability
- [ ] Have we stress-tested the system under adversarial or edge cases?  
- [ ] Do we have monitoring in place to detect failures or misuse?  
- [ ] What is the fallback or ‚Äúgraceful failure‚Äù mode if the AI produces harmful outputs?  

---

## 3. Transparency & Accountability
- [ ] Is it clear who is responsible for this system‚Äôs outputs and impacts?  
- [ ] Can we explain how the system makes its decisions (to an expert and to a layperson)?  
- [ ] Do we disclose when users are interacting with AI vs. a human?  

---

## 4. Bias & Fairness
- [ ] Have datasets been reviewed for bias or gaps?  
- [ ] Have outputs been tested across diverse demographic groups?  
- [ ] Do we have a plan for continuous auditing and improvement of fairness?  

---

## 5. Environmental Impact
- [ ] Have we measured the energy and compute footprint of training/inference?  
- [ ] Are we choosing greener infrastructure where feasible?  
- [ ] Is the system aligned with long-term sustainability goals?  

---

## 6. Data Privacy & Security
- [ ] Are we minimizing data collection to only what is necessary?  
- [ ] Is sensitive data properly anonymized, encrypted, or secured?  
- [ ] Have we considered risks of data leakage, model inversion, or re-identification?  

---

## 7. Governance & Stewardship
- [ ] Do we have clear internal policies on acceptable vs. unacceptable uses?  
- [ ] Are external stakeholders (users, communities, regulators) included in oversight?  
- [ ] Are adoption and updates aligned with broader ethical frameworks (e.g., AI-Human Covenant)?  

---

‚úÖ **How to use this checklist:**  
- Fill it out before launch, and update periodically as systems evolve.  
- Treat it as part of a *living governance process* ‚Äî not a one-time form.  
- If any box is unchecked, document why and what mitigation is planned.  

---

*Adapted from best practices in AI ethics, safety, and governance. Contributions welcome.*
